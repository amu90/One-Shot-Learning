{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akaur\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import load_model,save_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import xception\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Lambda\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from math import sqrt\n",
    "from keras.callbacks import History \n",
    "import gc\n",
    "from numpy.random import randint, choice\n",
    "import numpy.random as rng\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def read_img(filepath, size):\n",
    "    img = image.load_img((filepath), target_size=size)\n",
    "    img = image.img_to_array(img,data_format='channels_last')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (45,45,3)\n",
    "imgSize=(45,45)\n",
    "\n",
    "basePath = \"C:/Users/akaur/Desktop/Deakin/Dataset\"\n",
    "trainPath = os.path.join(basePath,'Train')\n",
    "testPath = os.path.join(basePath,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Details: \n",
    "The OMNIGLOT dataset consists of character lists of several languages, with each character having 20 images each. \n",
    "\n",
    "For the purpose of training/testing, I chose the characters of the Armenian Language. I chose the language as it was a sufficiently difficult task given the similarity of the languages.\n",
    "\n",
    "Given the task of one-shot learning, I chose to explore 2 different models:\n",
    "\n",
    "1.\tBasic CNN\n",
    "2.\tSiamese Networks (With CNN Base network)\n",
    "\n",
    "\n",
    "The dropout regularisation technique is used for reducing the overfitting in neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "superList = []\n",
    "folderList = sorted( os.listdir(trainPath))\n",
    "numPairs = 5000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5150\n"
     ]
    }
   ],
   "source": [
    "# Adding positive samples\n",
    "\n",
    "for folder in folderList:\n",
    "    \n",
    "    imgList = os.listdir(os.path.join(trainPath,folder))\n",
    "    \n",
    "    pairList = []\n",
    "    \n",
    "    for x in range(len(imgList)-1):\n",
    "        for y in range(x+1, len(imgList)):\n",
    "            \n",
    "            img1 = read_img(os.path.join(trainPath,folder,imgList[x]) , imgSize)\n",
    "            img2 = read_img(os.path.join(trainPath,folder,imgList[y]) , imgSize)\n",
    "            \n",
    "            pairList.append(((img1,img2),1))\n",
    "            \n",
    "    np.random.shuffle(pairList)\n",
    "    finalList = pairList[:150]\n",
    "    superList = superList + finalList\n",
    "    \n",
    "\n",
    "for i in range(2000):\n",
    "    \n",
    "    folder = choice(folderList)\n",
    "    \n",
    "    imgList = choice( os.listdir(os.path.join(trainPath,folder)), 2, replace = False ) \n",
    "    \n",
    "    img1 = read_img(os.path.join(trainPath,folder,imgList[0]), imgSize)\n",
    "    img2 = read_img(os.path.join(trainPath,folder,imgList[1]), imgSize)\n",
    "    \n",
    "    superList.append(((img1,img2),1))\n",
    "    \n",
    "\n",
    "print(len(superList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(folderList)-1):\n",
    "    for j in range(i,len(folderList)):\n",
    "        \n",
    "        pairList = []\n",
    "        \n",
    "        folder1 = folderList[i]\n",
    "        folder2 = folderList[j]\n",
    "        \n",
    "        #print(\"{} {}\".format(folder1,folder2))\n",
    "        \n",
    "        imgList1 = os.listdir(os.path.join(trainPath,folder1))\n",
    "        imgList2 = os.listdir(os.path.join(trainPath,folder2))\n",
    "        \n",
    "        for x in range(len(imgList1)):\n",
    "            for y in range(len(imgList2)):\n",
    "                \n",
    "                img1 = read_img(os.path.join(trainPath,folder1,imgList1[x]) , imgSize)\n",
    "                img2 = read_img(os.path.join(trainPath,folder2,imgList2[y]) , imgSize)\n",
    "                \n",
    "                pairList.append(((img1,img2),0))\n",
    "        \n",
    "        np.random.shuffle(pairList)\n",
    "        finalList = pairList[:35]\n",
    "        superList = superList+finalList\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(superList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(folder1,img1,folder2,img2,train1=True,train2=True):\n",
    "    \n",
    "    \n",
    "    if train1 == True:\n",
    "        image1 = sorted(os.listdir(os.path.join(trainPath,folder1)))[img1]\n",
    "        image1 = read_img(os.path.join(trainPath,folder1,image1), imgSize)\n",
    "    else:\n",
    "        image1 = sorted(os.listdir(os.path.join(testPath,folder1)))[img1]\n",
    "        image1 = read_img(os.path.join(testPath,folder1,image1), imgSize)\n",
    "        \n",
    "    if train2 == True:\n",
    "        image2 = sorted(os.listdir(os.path.join(trainPath,folder2)))[img2]\n",
    "        image2 = read_img(os.path.join(trainPath,folder2,image2), imgSize)\n",
    "    else:\n",
    "        image2 = sorted(os.listdir(os.path.join(testPath,folder2)))[img2]\n",
    "        \n",
    "        image2 = read_img(os.path.join(testPath,folder2,image2), imgSize)\n",
    "        \n",
    "    plt.subplot(211)\n",
    "    plt.imshow(image1)\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.imshow(image2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0028_18.png\n",
      "[[0.60623467]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAAD8CAYAAACsCeyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAACwZJREFUeJzt3c2LHPUWxvHvc6PRhYjGkRDy4ihmk50QoqALUQSNYu5CxCDiIpCNQkRBo/4DuvFl4UaMkIXgO9wQAqJjsnATM9GgJMFkDDdoiCYBRXEjwXMXXYNt7syZ6qnq6uqa5wNDurprpg7h6VO//s1vqhQRmM3nX6MuwNrNAbGUA2IpB8RSDoilHBBLOSCWqhQQSfdK+k7SjKSddRVl7aHFTpRJWgacAO4BfgQOAVsj4lh95dmoXVbhezcBMxFxCkDSu8AWYN6ATExMxOTkZIVDWl0OHz58ISKuX2i/KgFZDfzQt/0jcOulO0naDmwHWLduHdPT0xUOaXWRdLrMfkMfpEbEmxGxMSI2Xn/9goG1lqkSkDPA2r7tNcVz1iFVAnIIWC/pRknLgUeAPfWUZW2x6DFIRFyU9CTwCbAMeDsijtZWmbVClUEqEbEP2FdTLdZCnkm1lANiKQfEUg6IpRwQSzkglnJALOWAWKrSRNlSIWne17r+h2fuIJZyQCzViVNMdgqYT12nhtljd/VU4w5iqU50kMWY652/UCfK9u1qJ3EHsVQnOsgg79r53vmD/vzZ5xYz/hkn7iCW6kQHGZaujScWwx3EUu4gc3Dn+Js7iKUcEEv5FNOnjlNL1ybM3EEsteQ7SFfe6cPiDmIpB6SiiOh0F3JALOWAWMoBsZQDYikHxFIOiKWW/ERZXbr6UdcdxFILBkTSWkn7JR2TdFTSjuL5FZI+lXSy+Pfa4ZdrTSvTQS4Cz0TEBuA24AlJG4CdwFRErAemim3rmAUDEhFnI+Kr4vHvwHF6l+HeAuwudtsN/HtYRdroDDQGkTQJ3AIcBFZGxNnipZ+AlfN8z3ZJ05Kmz58/X6FUG4XSAZF0FfAR8FRE/Nb/WvSG8HMO49t+rXZJtXx1VamASLqcXjjeiYiPi6d/lrSqeH0VcG44JdoolfkUI2AXcDwiXul7aQ/wePH4ceA/9Zc3PrraScpMlN0OPAZ8K+lI8dwLwEvA+5K2AaeBh4dToo3SggGJiC+A+d4ad9dbjrWNp9pr4ql2W5KWfAfp6ju/Lu4glnJALOWAWMoBsZQDYikHxFIOiKUcEEs5IJZyQCzlgFjKAbGUA2IpB8RSDoilHBBLOSCWckAs5YBYqvNrUhf6Y6a5Xvc61b+5g1jKAZlDV/+McjEcEEt1fgyymNuXegzyN3cQS3W+g8xyV1gcdxBLOSCWckAs5YBYygGxlANiqUGuk7pM0teS9hbbN0o6KGlG0nuSlg+vTBuVQTrIDnqX4Z71MvBqRNwM/AJsq7Mwa4eyF9JdA9wPvFVsC7gL+LDYxddq76iyHeQ14Fngr2L7OuDXiLhYbP9I7wL//8fXah9vZa60/ABwLiIOL+YAbb9Wu+XKXmn5QUmbgSuBq4HXgWskXVZ0kTXAmeGVaaNS5n4xz0fEmoiYBB4BPo+IR4H9wEPFbkv+Wu1dVWUe5DngaUkz9MYku+opydpkoF/3R8QB4EDx+BSwqf6SrE08k2opB8RSDoilHBBLqcm1mpLOA38AFxo7aHUTdLPeGyJiwZnLRgMCIGk6IjY2etAKlnq9PsVYygGx1CgC8uYIjlnFkq638TGIjRefYizlgFiqsYBIulfSd8Ui551NHbcsSWsl7Zd0TNJRSTuK51dI+lTSyeLfa0dda79hLyZvJCCSlgFvAPcBG4CtkjY0cewBXASeiYgNwG3AE0WNO4GpiFgPTBXbbTLUxeRNdZBNwExEnIqIP4F3gS0NHbuUiDgbEV8Vj3+n95++ml6du4vdWrU4u4nF5E0FZDXwQ9/2vIuc20DSJHALcBBYGRFni5d+AlaOqKy5LHoxeVkepF5C0lXAR8BTEfFb/2vRmxNoxbxA1cXkZTV1AZkzwNq+7VYucpZ0Ob1wvBMRHxdP/yxpVUSclbQKODe6Cv+hkcXkTXWQQ8D6YoS9nN7i5z0NHbuU4vy9CzgeEa/0vbSH3qJsaNHi7MYWk0dEI1/AZuAE8D3wYlPHHaC+O+idPr4BjhRfm+md16eAk8BnwIpR1zpH7XcCe4vHNwFfAjPAB8AVVX62p9otVekU0/bJL6tu0R2kmPw6AdxD7+PUIWBrRByrrzwbtSodpPWTX1ZdlY+5c01+3Zp9w8TERExOTlY4pNXl8OHDF6LEmtShz4NI2g5sB1i3bh3T09PDPqSVIOl0mf2qnGJKTX6FL/8w1qoEpPWTX1bdok8xEXFR0pPAJ8Ay4O2IOFpbZdYKlcYgEbEP2FdTLdZC/m2upRwQSzkglnJALOWAWMoBsZQDYqklc1PDS5W5TaoXU7mD2AI630Gq3GJ99nuXcidxB7GUA2IpB8RSDoilOj9IHWSAWceAtmoNbeMOYqnOd5BhGaTbjPPHZXcQS7mDlFBlbDLXzxmnTuIOYil3kJpc2hWyrjNOncQdxFIOiKV8ihnAIKeEufa99LQzDqcadxBLuYOUUNc7fPbn1PWxuQnuIJZyB2mB/o7StvGIO4ilHBBLOSCW8hhkBNo2zsi4g1jKAbGUA2KpBQMyrjf7s3qU6SDjerM/q8GCAYkxvNmf1WegMcgY3ezPalI6IIu92Z+k7ZKmJU2fP3++UrHWvFIByW72V7w+783+fK328VbmU8xY3ezP6lVmqv124DHgW0lHiudeAF4C3pe0DTgNPDycEm2UFgxIRHwBzLcE6u56y7G28UyqpRwQSzkglnJALOWAWMoBsZQDYikHxFIOiKW8qr2Euv+W1qvarTMcEEs5IJZyQCzlQWoJ4zSorJs7iKUcEEs5IJZyQCzlgFjKAbGUA2IpB8RSDoilHBBLOSCWckAstWR+WTesmybPpyu/4HMHsZQDYikHxFJLZgzSlTFB09xBLOWAWMoBsdQg10ldJulrSXuL7RslHZQ0I+k9ScuHV6aNyiAdZAe9y3DPehl4NSJuBn4BttVZmLVD2QvprgHuB94qtgXcBXxY7OJrtXdU2Q7yGvAs8FexfR3wa0RcLLZ/pHeBf+uYMldafgA4FxGHF3MAX6t9vJXpILcDD0r6L/AuvVPL68A1kmYn2tYAZ+b6Zl+rfbyVuV/M8xGxJiImgUeAzyPiUWA/8FCxm6/V3lFV5kGeA56WNENvTLKrnpKsTQb6XUxEHAAOFI9PAZvqL8naxDOplnJALOWAWMoBsZQDYik1udJK0nngD+BCYwetboJu1ntDRCw4c9loQAAkTUfExkYPWsFSr9enGEs5IJYaRUDeHMExq1jS9TY+BrHx4lOMpRoLiKR7JX1XLHLe2dRxy5K0VtJ+ScckHZW0o3h+haRPJZ0s/r121LX2G/Zi8kYCImkZ8AZwH7AB2CppQxPHHsBF4JmI2ADcBjxR1LgTmIqI9cBUsd0mQ11M3lQH2QTMRMSpiPiT3sq0LQ0du5SIOBsRXxWPf6f3n76aXp27i91atTi7icXkTQVkNfBD33arFzlLmgRuAQ4CKyPibPHST8DKEZU1l6EvJvcg9RKSrgI+Ap6KiN/6X4veR75WfOyrupi8rKb+uv8MsLZve95FzqMk6XJ64XgnIj4unv5Z0qqIOCtpFXBudBX+w+xi8s3AlcDV9C0mL7pI5f/npjrIIWB9McJeTm/x856Gjl1Kcf7eBRyPiFf6XtpDb1E2tGhxdmOLySOikS9gM3AC+B54sanjDlDfHfROH98AR4qvzfTO61PASeAzYMWoa52j9juBvcXjm4AvgRngA+CKKj/bM6mW8iDVUg6IpRwQSzkglnJALOWAWMoBsZQDYqn/AVU2Vtg3kiNNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image('character02',5,'character02',2,train1= True, train2= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection\n",
    "\n",
    "The major challenge with One-Shot Learning is the limited amount of data available to classify between numerous classes. Given the nature of the dataset, CNN was chosen since its the default neural network choice for working with images. However, given the need of basic CNNs for large amounts of data to work properly, we also look at a variant known as Siamese Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = Sequential()\n",
    "baseModel.add(BatchNormalization(input_shape = input_dim))\n",
    "baseModel.add(Conv2D(64, (7,7),activation='relu', data_format='channels_last',kernel_initializer=W_init))\n",
    "baseModel.add(MaxPooling2D())\n",
    "\n",
    "baseModel.add(Dropout(0.3))\n",
    "baseModel.add(Conv2D(128, (5,5),activation='relu',kernel_initializer=W_init, bias_initializer=b_init))\n",
    "baseModel.add(Dropout(0.3))\n",
    "baseModel.add(Conv2D(256, (3,3),activation='relu',kernel_initializer=W_init, bias_initializer=b_init))\n",
    "baseModel.add(Flatten())\n",
    "baseModel.add(Dense(1028, activation='relu'))\n",
    "# baseModel.add(Dense(32, activation='relu'))\n",
    "\n",
    "\n",
    "inputA = Input(shape = input_dim)\n",
    "inputB = Input(shape = input_dim)\n",
    "\n",
    "outputA = baseModel(inputA)\n",
    "outputB = baseModel(inputB)\n",
    "\n",
    "\n",
    "#Extracting data\n",
    "inputAimgs = np.array([x[0][0] for x in superList])\n",
    "inputBimgs = np.array([x[0][1] for x in superList])\n",
    "target = np.array([x[1] for x in superList])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions used : \n",
    "CNN uses Crossentropy as the loss function\n",
    "and Siamese Network uses Contrastive Loss as the loss function. I used Adadelta optimiser because of its adaptive learning rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([outputA, outputB])\n",
    "prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "CNN = Model(inputs=[inputA,inputB],outputs=prediction)\n",
    "\n",
    "CNN.compile(loss=\"binary_crossentropy\",optimizer='adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5150/5150 [==============================] - 608s 118ms/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 2/10\n",
      "5150/5150 [==============================] - 568s 110ms/step - loss: 6.0920e-06 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "5150/5150 [==============================] - 615s 119ms/step - loss: 3.6415e-06 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "5150/5150 [==============================] - 634s 123ms/step - loss: 2.0139e-06 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "5150/5150 [==============================] - 675s 131ms/step - loss: 1.0196e-06 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "5150/5150 [==============================] - 971s 189ms/step - loss: 1.3161e-06 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "5150/5150 [==============================] - 36337s 7s/step - loss: 8.7138e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "5150/5150 [==============================] - 696s 135ms/step - loss: 7.6264e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "5150/5150 [==============================] - 845s 164ms/step - loss: 4.5746e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "5150/5150 [==============================] - 750s 146ms/step - loss: 6.7034e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c23db14630>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN.fit([inputAimgs,inputBimgs], target, batch_size = 20,epochs = 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akaur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([outputA,outputB])\n",
    "\n",
    "Siamese = Model(input=[inputA, inputB], output=distance)\n",
    "\n",
    "Siamese.compile(loss=contrastive_loss,optimizer='adadelta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21390/21390 [==============================] - 112s 5ms/step - loss: 0.1940\n",
      "Epoch 2/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.1344\n",
      "Epoch 3/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.1115\n",
      "Epoch 4/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.1018\n",
      "Epoch 5/10\n",
      "21390/21390 [==============================] - 110s 5ms/step - loss: 0.0942\n",
      "Epoch 6/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.0893\n",
      "Epoch 7/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.0855\n",
      "Epoch 8/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.0823\n",
      "Epoch 9/10\n",
      "21390/21390 [==============================] - 108s 5ms/step - loss: 0.0795\n",
      "Epoch 10/10\n",
      "21390/21390 [==============================] - 107s 5ms/step - loss: 0.0764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ae32af590>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Siamese.fit([inputAimgs,inputBimgs], target, batch_size = 30,epochs = 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metrics/Loss Functions\n",
    " Since the task involved is a classification one, I have used accuracy as the performance metric for the task. An important difference however, is the number of classes being used in the testing process. Since One-Shot learning focuses on the ability to classify a large number of classes based on lesser amounts of data, the accuracy is tested for different number of classes. This is known as N-way accuracy.For eg., while testing, if only 20 classes are considered for classification, then it is known as 20-way accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getSupportImgs(path):\n",
    "    \n",
    "    supportImg=[]\n",
    "    \n",
    "    os.chdir(path)\n",
    "    folderList = os.listdir(\"./\")\n",
    "    \n",
    "    for folder in folderList:\n",
    "        os.chdir(os.path.join(path,folder))\n",
    "        imgList = os.listdir(\"./\")\n",
    "        \n",
    "        img = read_img(os.path.join(path,folder,choice(imgList)), imgSize)\n",
    "        supportImg.append([img,folder])\n",
    "        \n",
    "    return(supportImg)\n",
    "        \n",
    "\n",
    "def predictBestFolder(img,label,trainPath,model,numImages = 5,printList = False,testClasses = 30):\n",
    "    \n",
    "    predList = []\n",
    "    \n",
    "    folderList = sorted(os.listdir(trainPath))[:testClasses]\n",
    "    \n",
    "    for folder in folderList:\n",
    "        \n",
    "        imgList = choice(os.listdir(os.path.join(trainPath,folder)), numImages, replace = False )\n",
    "        folderPreds = []\n",
    "        \n",
    "        for i in range(numImages):\n",
    "            folderImg = read_img(os.path.join(trainPath,folder,imgList[i]), imgSize )\n",
    "            pred = model.predict([img.reshape(1,imgSize[0],imgSize[1],3), folderImg.reshape(1,imgSize[0],imgSize[1],3)])\n",
    "            folderPreds.append(pred)\n",
    "        \n",
    "        predList.append([folder, np.mean(folderPreds)])\n",
    "    \n",
    "    predList = sorted(predList, key = lambda x:x[1])\n",
    "    \n",
    "    if printList == True:\n",
    "        print(predList)\n",
    "        \n",
    "    return(predList[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Accuracy of Siamese model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img : 0027_20.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_16.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_19.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_18.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_17.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0028_20.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_17.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_18.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_16.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_19.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0029_19.png True Label : character03  Predicted Label : character03 Accuracy : 1.0\n",
      "Img : 0029_16.png True Label : character03  Predicted Label : character03 Accuracy : 1.0\n",
      "Img : 0029_18.png True Label : character03  Predicted Label : character03 Accuracy : 1.0\n",
      "Img : 0029_20.png True Label : character03  Predicted Label : character03 Accuracy : 1.0\n",
      "Img : 0029_17.png True Label : character03  Predicted Label : character03 Accuracy : 1.0\n",
      "Img : 0030_17.png True Label : character04  Predicted Label : character04 Accuracy : 1.0\n",
      "Img : 0030_19.png True Label : character04  Predicted Label : character04 Accuracy : 1.0\n",
      "Img : 0030_16.png True Label : character04  Predicted Label : character04 Accuracy : 1.0\n",
      "Img : 0030_18.png True Label : character04  Predicted Label : character18 Accuracy : 0.947\n",
      "Img : 0030_20.png True Label : character04  Predicted Label : character04 Accuracy : 0.95\n",
      "Img : 0031_19.png True Label : character05  Predicted Label : character07 Accuracy : 0.905\n",
      "Img : 0031_20.png True Label : character05  Predicted Label : character05 Accuracy : 0.909\n",
      "Img : 0031_18.png True Label : character05  Predicted Label : character05 Accuracy : 0.913\n",
      "Img : 0031_16.png True Label : character05  Predicted Label : character05 Accuracy : 0.917\n",
      "Img : 0031_17.png True Label : character05  Predicted Label : character04 Accuracy : 0.88\n",
      "Img : 0032_18.png True Label : character06  Predicted Label : character20 Accuracy : 0.846\n",
      "Img : 0032_20.png True Label : character06  Predicted Label : character06 Accuracy : 0.852\n",
      "Img : 0032_16.png True Label : character06  Predicted Label : character06 Accuracy : 0.857\n",
      "Img : 0032_19.png True Label : character06  Predicted Label : character03 Accuracy : 0.828\n",
      "Img : 0032_17.png True Label : character06  Predicted Label : character18 Accuracy : 0.8\n",
      "Img : 0033_20.png True Label : character07  Predicted Label : character07 Accuracy : 0.806\n",
      "Img : 0033_19.png True Label : character07  Predicted Label : character07 Accuracy : 0.813\n",
      "Img : 0033_17.png True Label : character07  Predicted Label : character07 Accuracy : 0.818\n",
      "Img : 0033_16.png True Label : character07  Predicted Label : character07 Accuracy : 0.824\n",
      "Img : 0033_18.png True Label : character07  Predicted Label : character07 Accuracy : 0.829\n",
      "Img : 0034_19.png True Label : character08  Predicted Label : character08 Accuracy : 0.833\n",
      "Img : 0034_20.png True Label : character08  Predicted Label : character08 Accuracy : 0.838\n",
      "Img : 0034_17.png True Label : character08  Predicted Label : character04 Accuracy : 0.816\n",
      "Img : 0034_18.png True Label : character08  Predicted Label : character11 Accuracy : 0.795\n",
      "Img : 0034_16.png True Label : character08  Predicted Label : character08 Accuracy : 0.8\n",
      "Img : 0035_17.png True Label : character09  Predicted Label : character09 Accuracy : 0.805\n",
      "Img : 0035_20.png True Label : character09  Predicted Label : character09 Accuracy : 0.81\n",
      "Img : 0035_19.png True Label : character09  Predicted Label : character09 Accuracy : 0.814\n",
      "Img : 0035_16.png True Label : character09  Predicted Label : character09 Accuracy : 0.818\n",
      "Img : 0035_18.png True Label : character09  Predicted Label : character09 Accuracy : 0.822\n",
      "Img : 0036_19.png True Label : character10  Predicted Label : character10 Accuracy : 0.826\n",
      "Img : 0036_17.png True Label : character10  Predicted Label : character10 Accuracy : 0.83\n",
      "Img : 0036_16.png True Label : character10  Predicted Label : character10 Accuracy : 0.833\n",
      "Img : 0036_20.png True Label : character10  Predicted Label : character10 Accuracy : 0.837\n",
      "Img : 0036_18.png True Label : character10  Predicted Label : character14 Accuracy : 0.82\n",
      "Img : 0037_19.png True Label : character11  Predicted Label : character11 Accuracy : 0.824\n",
      "Img : 0037_20.png True Label : character11  Predicted Label : character05 Accuracy : 0.808\n",
      "Img : 0037_17.png True Label : character11  Predicted Label : character11 Accuracy : 0.811\n",
      "Img : 0037_16.png True Label : character11  Predicted Label : character11 Accuracy : 0.815\n",
      "Img : 0037_18.png True Label : character11  Predicted Label : character16 Accuracy : 0.8\n",
      "Img : 0038_18.png True Label : character12  Predicted Label : character12 Accuracy : 0.804\n",
      "Img : 0038_16.png True Label : character12  Predicted Label : character12 Accuracy : 0.807\n",
      "Img : 0038_20.png True Label : character12  Predicted Label : character12 Accuracy : 0.81\n",
      "Img : 0038_17.png True Label : character12  Predicted Label : character12 Accuracy : 0.814\n",
      "Img : 0038_19.png True Label : character12  Predicted Label : character12 Accuracy : 0.817\n",
      "Img : 0039_17.png True Label : character13  Predicted Label : character13 Accuracy : 0.82\n",
      "Img : 0039_18.png True Label : character13  Predicted Label : character13 Accuracy : 0.823\n",
      "Img : 0039_19.png True Label : character13  Predicted Label : character13 Accuracy : 0.825\n",
      "Img : 0039_16.png True Label : character13  Predicted Label : character13 Accuracy : 0.828\n",
      "Img : 0039_20.png True Label : character13  Predicted Label : character13 Accuracy : 0.831\n",
      "Img : 0040_20.png True Label : character14  Predicted Label : character14 Accuracy : 0.833\n",
      "Img : 0040_16.png True Label : character14  Predicted Label : character05 Accuracy : 0.821\n",
      "Img : 0040_18.png True Label : character14  Predicted Label : character14 Accuracy : 0.824\n",
      "Img : 0040_17.png True Label : character14  Predicted Label : character14 Accuracy : 0.826\n",
      "Img : 0040_19.png True Label : character14  Predicted Label : character14 Accuracy : 0.829\n",
      "Img : 0041_17.png True Label : character15  Predicted Label : character16 Accuracy : 0.817\n",
      "Img : 0041_20.png True Label : character15  Predicted Label : character15 Accuracy : 0.819\n",
      "Img : 0041_16.png True Label : character15  Predicted Label : character15 Accuracy : 0.822\n",
      "Img : 0041_19.png True Label : character15  Predicted Label : character16 Accuracy : 0.811\n",
      "Img : 0041_18.png True Label : character15  Predicted Label : character15 Accuracy : 0.813\n",
      "Img : 0042_18.png True Label : character16  Predicted Label : character16 Accuracy : 0.816\n",
      "Img : 0042_17.png True Label : character16  Predicted Label : character05 Accuracy : 0.805\n",
      "Img : 0042_16.png True Label : character16  Predicted Label : character05 Accuracy : 0.795\n",
      "Img : 0042_20.png True Label : character16  Predicted Label : character16 Accuracy : 0.797\n",
      "Img : 0042_19.png True Label : character16  Predicted Label : character16 Accuracy : 0.8\n",
      "Img : 0043_18.png True Label : character17  Predicted Label : character17 Accuracy : 0.802\n",
      "Img : 0043_17.png True Label : character17  Predicted Label : character17 Accuracy : 0.805\n",
      "Img : 0043_19.png True Label : character17  Predicted Label : character17 Accuracy : 0.807\n",
      "Img : 0043_20.png True Label : character17  Predicted Label : character17 Accuracy : 0.81\n",
      "Img : 0043_16.png True Label : character17  Predicted Label : character17 Accuracy : 0.812\n",
      "Img : 0044_20.png True Label : character18  Predicted Label : character04 Accuracy : 0.802\n",
      "Img : 0044_17.png True Label : character18  Predicted Label : character04 Accuracy : 0.793\n",
      "Img : 0044_16.png True Label : character18  Predicted Label : character18 Accuracy : 0.795\n",
      "Img : 0044_19.png True Label : character18  Predicted Label : character04 Accuracy : 0.787\n",
      "Img : 0044_18.png True Label : character18  Predicted Label : character18 Accuracy : 0.789\n",
      "Img : 0045_18.png True Label : character19  Predicted Label : character19 Accuracy : 0.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img : 0045_17.png True Label : character19  Predicted Label : character19 Accuracy : 0.793\n",
      "Img : 0045_20.png True Label : character19  Predicted Label : character19 Accuracy : 0.796\n",
      "Img : 0045_16.png True Label : character19  Predicted Label : character19 Accuracy : 0.798\n",
      "Img : 0045_19.png True Label : character19  Predicted Label : character19 Accuracy : 0.8\n",
      "Img : 0046_18.png True Label : character20  Predicted Label : character20 Accuracy : 0.802\n",
      "Img : 0046_17.png True Label : character20  Predicted Label : character20 Accuracy : 0.804\n",
      "Img : 0046_20.png True Label : character20  Predicted Label : character20 Accuracy : 0.806\n",
      "Img : 0046_16.png True Label : character20  Predicted Label : character20 Accuracy : 0.808\n",
      "Img : 0046_19.png True Label : character20  Predicted Label : character20 Accuracy : 0.81\n",
      "Accuracy : 0.81\n"
     ]
    }
   ],
   "source": [
    "# 20-way testing\n",
    "\n",
    "os.chdir(testPath)\n",
    "folderList = sorted(os.listdir(\"./\"))[:20]\n",
    "\n",
    "correctPred = 0\n",
    "testImageCount = 0\n",
    "\n",
    "for folder in folderList:\n",
    "    os.chdir(os.path.join(testPath,folder))\n",
    "    imgList = os.listdir(\"./\")\n",
    "    \n",
    "    for img in imgList:\n",
    "        imgName = img\n",
    "        testImageCount+=1\n",
    "        \n",
    "        img = read_img(os.path.join(testPath,folder,img), imgSize)\n",
    "        bestLabel = predictBestFolder(img,folder,trainPath,Siamese,15,testClasses=20)[0]\n",
    "        \n",
    "        if bestLabel == folder:\n",
    "            correctPred+=1\n",
    "        acc = round(correctPred/float(testImageCount),3)\n",
    "        print(\"Img : {} True Label : {}  Predicted Label : {} Accuracy : {}\".format(imgName,folder,bestLabel,acc))\n",
    "        \n",
    "accuracy = correctPred/float(testImageCount)\n",
    "print(\"Accuracy : {}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,'./bestModel_0.81.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of CNN on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img : 0027_16.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_17.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_18.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_19.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0027_20.png True Label : character01  Predicted Label : character01 Accuracy : 1.0\n",
      "Img : 0028_16.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_17.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_18.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_19.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0028_20.png True Label : character02  Predicted Label : character02 Accuracy : 1.0\n",
      "Img : 0029_16.png True Label : character03  Predicted Label : character07 Accuracy : 0.909\n",
      "Img : 0029_17.png True Label : character03  Predicted Label : character03 Accuracy : 0.917\n",
      "Img : 0029_18.png True Label : character03  Predicted Label : character01 Accuracy : 0.846\n",
      "Img : 0029_19.png True Label : character03  Predicted Label : character01 Accuracy : 0.786\n",
      "Img : 0029_20.png True Label : character03  Predicted Label : character03 Accuracy : 0.8\n",
      "Img : 0030_16.png True Label : character04  Predicted Label : character03 Accuracy : 0.75\n",
      "Img : 0030_17.png True Label : character04  Predicted Label : character18 Accuracy : 0.706\n",
      "Img : 0030_18.png True Label : character04  Predicted Label : character04 Accuracy : 0.722\n",
      "Img : 0030_19.png True Label : character04  Predicted Label : character20 Accuracy : 0.684\n",
      "Img : 0030_20.png True Label : character04  Predicted Label : character18 Accuracy : 0.65\n",
      "Img : 0031_16.png True Label : character05  Predicted Label : character02 Accuracy : 0.619\n",
      "Img : 0031_17.png True Label : character05  Predicted Label : character01 Accuracy : 0.591\n",
      "Img : 0031_18.png True Label : character05  Predicted Label : character03 Accuracy : 0.565\n",
      "Img : 0031_19.png True Label : character05  Predicted Label : character18 Accuracy : 0.542\n",
      "Img : 0031_20.png True Label : character05  Predicted Label : character17 Accuracy : 0.52\n",
      "Img : 0032_16.png True Label : character06  Predicted Label : character03 Accuracy : 0.5\n",
      "Img : 0032_17.png True Label : character06  Predicted Label : character01 Accuracy : 0.481\n",
      "Img : 0032_18.png True Label : character06  Predicted Label : character01 Accuracy : 0.464\n",
      "Img : 0032_19.png True Label : character06  Predicted Label : character04 Accuracy : 0.448\n",
      "Img : 0032_20.png True Label : character06  Predicted Label : character06 Accuracy : 0.467\n",
      "Img : 0033_16.png True Label : character07  Predicted Label : character12 Accuracy : 0.452\n",
      "Img : 0033_17.png True Label : character07  Predicted Label : character05 Accuracy : 0.438\n",
      "Img : 0033_18.png True Label : character07  Predicted Label : character08 Accuracy : 0.424\n",
      "Img : 0033_19.png True Label : character07  Predicted Label : character12 Accuracy : 0.412\n",
      "Img : 0033_20.png True Label : character07  Predicted Label : character16 Accuracy : 0.4\n",
      "Img : 0034_16.png True Label : character08  Predicted Label : character11 Accuracy : 0.389\n",
      "Img : 0034_17.png True Label : character08  Predicted Label : character08 Accuracy : 0.405\n",
      "Img : 0034_18.png True Label : character08  Predicted Label : character01 Accuracy : 0.395\n",
      "Img : 0034_19.png True Label : character08  Predicted Label : character11 Accuracy : 0.385\n",
      "Img : 0034_20.png True Label : character08  Predicted Label : character08 Accuracy : 0.4\n",
      "Img : 0035_16.png True Label : character09  Predicted Label : character09 Accuracy : 0.415\n",
      "Img : 0035_17.png True Label : character09  Predicted Label : character01 Accuracy : 0.405\n",
      "Img : 0035_18.png True Label : character09  Predicted Label : character01 Accuracy : 0.395\n",
      "Img : 0035_19.png True Label : character09  Predicted Label : character01 Accuracy : 0.386\n",
      "Img : 0035_20.png True Label : character09  Predicted Label : character01 Accuracy : 0.378\n",
      "Img : 0036_16.png True Label : character10  Predicted Label : character01 Accuracy : 0.37\n",
      "Img : 0036_17.png True Label : character10  Predicted Label : character01 Accuracy : 0.362\n",
      "Img : 0036_18.png True Label : character10  Predicted Label : character10 Accuracy : 0.375\n",
      "Img : 0036_19.png True Label : character10  Predicted Label : character14 Accuracy : 0.367\n",
      "Img : 0036_20.png True Label : character10  Predicted Label : character01 Accuracy : 0.36\n",
      "Img : 0037_16.png True Label : character11  Predicted Label : character16 Accuracy : 0.353\n",
      "Img : 0037_17.png True Label : character11  Predicted Label : character08 Accuracy : 0.346\n",
      "Img : 0037_18.png True Label : character11  Predicted Label : character15 Accuracy : 0.34\n",
      "Img : 0037_19.png True Label : character11  Predicted Label : character16 Accuracy : 0.333\n",
      "Img : 0037_20.png True Label : character11  Predicted Label : character16 Accuracy : 0.327\n",
      "Img : 0038_16.png True Label : character12  Predicted Label : character01 Accuracy : 0.321\n",
      "Img : 0038_17.png True Label : character12  Predicted Label : character12 Accuracy : 0.333\n",
      "Img : 0038_18.png True Label : character12  Predicted Label : character07 Accuracy : 0.328\n",
      "Img : 0038_19.png True Label : character12  Predicted Label : character12 Accuracy : 0.339\n",
      "Img : 0038_20.png True Label : character12  Predicted Label : character12 Accuracy : 0.35\n",
      "Img : 0039_16.png True Label : character13  Predicted Label : character01 Accuracy : 0.344\n",
      "Img : 0039_17.png True Label : character13  Predicted Label : character01 Accuracy : 0.339\n",
      "Img : 0039_18.png True Label : character13  Predicted Label : character01 Accuracy : 0.333\n",
      "Img : 0039_19.png True Label : character13  Predicted Label : character17 Accuracy : 0.328\n",
      "Img : 0039_20.png True Label : character13  Predicted Label : character01 Accuracy : 0.323\n",
      "Img : 0040_16.png True Label : character14  Predicted Label : character17 Accuracy : 0.318\n",
      "Img : 0040_17.png True Label : character14  Predicted Label : character14 Accuracy : 0.328\n",
      "Img : 0040_18.png True Label : character14  Predicted Label : character01 Accuracy : 0.324\n",
      "Img : 0040_19.png True Label : character14  Predicted Label : character14 Accuracy : 0.333\n",
      "Img : 0040_20.png True Label : character14  Predicted Label : character14 Accuracy : 0.343\n",
      "Img : 0041_16.png True Label : character15  Predicted Label : character07 Accuracy : 0.338\n",
      "Img : 0041_17.png True Label : character15  Predicted Label : character15 Accuracy : 0.347\n",
      "Img : 0041_18.png True Label : character15  Predicted Label : character03 Accuracy : 0.342\n",
      "Img : 0041_19.png True Label : character15  Predicted Label : character01 Accuracy : 0.338\n",
      "Img : 0041_20.png True Label : character15  Predicted Label : character18 Accuracy : 0.333\n",
      "Img : 0042_16.png True Label : character16  Predicted Label : character20 Accuracy : 0.329\n",
      "Img : 0042_17.png True Label : character16  Predicted Label : character01 Accuracy : 0.325\n",
      "Img : 0042_18.png True Label : character16  Predicted Label : character01 Accuracy : 0.321\n",
      "Img : 0042_19.png True Label : character16  Predicted Label : character16 Accuracy : 0.329\n",
      "Img : 0042_20.png True Label : character16  Predicted Label : character01 Accuracy : 0.325\n",
      "Img : 0043_16.png True Label : character17  Predicted Label : character16 Accuracy : 0.321\n",
      "Img : 0043_17.png True Label : character17  Predicted Label : character17 Accuracy : 0.329\n",
      "Img : 0043_18.png True Label : character17  Predicted Label : character15 Accuracy : 0.325\n",
      "Img : 0043_19.png True Label : character17  Predicted Label : character01 Accuracy : 0.321\n",
      "Img : 0043_20.png True Label : character17  Predicted Label : character15 Accuracy : 0.318\n",
      "Img : 0044_16.png True Label : character18  Predicted Label : character06 Accuracy : 0.314\n",
      "Img : 0044_17.png True Label : character18  Predicted Label : character01 Accuracy : 0.31\n",
      "Img : 0044_18.png True Label : character18  Predicted Label : character01 Accuracy : 0.307\n",
      "Img : 0044_19.png True Label : character18  Predicted Label : character01 Accuracy : 0.303\n",
      "Img : 0044_20.png True Label : character18  Predicted Label : character18 Accuracy : 0.311\n",
      "Img : 0045_16.png True Label : character19  Predicted Label : character05 Accuracy : 0.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img : 0045_17.png True Label : character19  Predicted Label : character17 Accuracy : 0.304\n",
      "Img : 0045_18.png True Label : character19  Predicted Label : character01 Accuracy : 0.301\n",
      "Img : 0045_19.png True Label : character19  Predicted Label : character08 Accuracy : 0.298\n",
      "Img : 0045_20.png True Label : character19  Predicted Label : character18 Accuracy : 0.295\n",
      "Img : 0046_16.png True Label : character20  Predicted Label : character01 Accuracy : 0.292\n",
      "Img : 0046_17.png True Label : character20  Predicted Label : character01 Accuracy : 0.289\n",
      "Img : 0046_18.png True Label : character20  Predicted Label : character20 Accuracy : 0.296\n",
      "Img : 0046_19.png True Label : character20  Predicted Label : character20 Accuracy : 0.303\n",
      "Img : 0046_20.png True Label : character20  Predicted Label : character20 Accuracy : 0.31\n",
      "Accuracy : 0.31\n"
     ]
    }
   ],
   "source": [
    "# 20-way testing\n",
    "\n",
    "os.chdir(testPath)\n",
    "folderList = sorted(os.listdir(\"./\"))[:20]\n",
    "\n",
    "correctPred = 0\n",
    "testImageCount = 0\n",
    "\n",
    "for folder in folderList:\n",
    "    os.chdir(os.path.join(testPath,folder))\n",
    "    imgList = os.listdir(\"./\")\n",
    "    \n",
    "    for img in imgList:\n",
    "        imgName = img\n",
    "        testImageCount+=1\n",
    "        \n",
    "        img = read_img(os.path.join(testPath,folder,img), imgSize)\n",
    "        bestLabel = predictBestFolder(img,folder,trainPath,CNN,15,testClasses=20)[0]\n",
    "        \n",
    "        if bestLabel == folder:\n",
    "            correctPred+=1\n",
    "        acc = round(correctPred/float(testImageCount),3)\n",
    "        print(\"Img : {} True Label : {}  Predicted Label : {} Accuracy : {}\".format(imgName,folder,bestLabel,acc))\n",
    "        \n",
    "accuracy = correctPred/float(testImageCount)\n",
    "print(\"Accuracy : {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results 20-way accuracy\n",
    "\n",
    "The Siamese Network model outperforms CNN model for one shot learning. \n",
    "\n",
    "The CNN model requires large amount of data to learn and adjust the parameters of the model. The less amount of data i.e. just few examples per image resulted in poor performace of CNN model. \n",
    "\n",
    "The similarity function in Siamese network that measures the degree of difference between images helps to learn the model from less amount of data while giving good performance results.\n",
    " \n",
    "\n",
    "CNN\t     31%\n",
    "Siamese Networks\t81%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
